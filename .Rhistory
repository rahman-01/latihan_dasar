iris
# Check the result
iris
install.packages("ggvis")
devtools::install_github("hadley/lazyeval", build_vignettes = FALSE)
# Iris scatter plot
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
cor(iris[iris$Species==x[3],1:4])
library ggvis
library(ggvis)
iris %>% ggvis(~Sepal.Length, ~Sepal.Width, fill = ~Species) %>% layer_points()
iris %>% ggvis(~Petal.Length, ~Petal.Width, fill = ~Species) %>% layer_points()
cor(iris[iris$Species==x[3],1:4])
# Return structure of `iris`
str(iris)
v <- 1:5
v <- c(1,2,3,4,5)
v <- seq(from=1,to=5,by=1)
v0 <- c(0,0,0,0,0,0)
v0 <- seq(from=0,to=0,length.out=6)
v1 <- c(1,2,3,4,5)
v2 <- c(6,7,8,9,10)
v3 <- c(11,12,13,14,15)
v4 <- c(16,17,18,19,20)
cbind(v1,v2,v3,v4)
rbind(v1,v2,v3,v4)
v <- seq(from=1,to=20,by=1)
matrix(v, nrow=4, ncol=5)
matrix(v, nrow=4, ncol=5, byrow=TRUE)
v <- seq(from=1,to=20,by=1)
matrix(v, nrow=4, ncol=5)
matrix(v, nrow=4, ncol=5, byrow=TRUE)
matrix20 <- matrix(v, nrow=4, ncol=5, byrow=TRUE)
colnames(matrix20) <- c("Col1","Col2","Col3","Col4","Col5")
rownames(matrix20) <- c("Row1","Row2","Row3","Row4")
v[3]
matrix20[,"Col2"]
matrix20["Row4",]
matrix20["Row3","Col1"]
matrix20[3,1]
length(v1)
setwd("D:/Belajar Data Scientis/R praktek/lat_dasar")
#Getting and Setting the Working Directory
# Get and print current working directory.
print(getwd())
# Set current working directory.
setwd("/web/com")
# Set current working directory.
setwd("/web/com")
# Set current working directory.
setwd("/R praktek/lat_dasar")
# Set current working directory.
setwd("/Belajar Data Scientis/R praktek/lat_dasar")
# Get and print current working directory.
print(getwd())
#Reading a CSV File
data <-read.csv("input.csv")
print(data)
#Analyzing the CSV File
data <- read.csv("input.csv")
print(is.data.frame(data))
print(ncol(data))
print(nrow(data))
#Get the maximum salary
data <- read.csv("input.csv")
# Get the max salary from data frame.
sal <- max(data$salary)
print(sal)
#Get the details of the person with max salary
# Create a data frame
data <- read.csv("input.csv")
# Get the max salary from data frame.
sal <- max(data$salary)
# Get the person detail having max salary.
retval <- subset(data,salary == max(salary))
print(retval)
#Get all the people working in IT department
# Create a data frame.
data <- read.csv("input.csv")
retval <- subset(data,dept == "IT")
print(retval)
#Get the persons in IT department whose salary is greater than 600
#create data frame
data <- read.csv("input.csv")
info <- subset(data,salary > 600 & dept == "IT")
print(info)
#Get the people who joined on or after 2014
data <-read.csv("input.csv")
retval <-subset(data,as.Date(start_date) > as.Date("2014-01-01"))
print(retval)
#Writing into a CSV File
#Create a data frame
data <-read.csv("input.csv")
retval <- subset(data,as.Date(start_date) > as.Date("2014-01-01"))
# Write filtered data into a new file.
write.csv(retval,"output.csv")
newdata <-read.csv("output.csv")
print(newdata)
# Create a data frame.
data <- read.csv("input.csv")
retval <- subset(data, as.Date(start_date) > as.Date("2014-01-01"))
# Write filtered data into a new file.
write.csv(retval,"output.csv", row.names = FALSE)
newdata <- read.csv("output.csv")
print(newdata)
# Read the "mtcars" data frame as a csv file and store only the columns
"cyl", "am" and "gear".
write.table(mtcars, file = "mtcars.csv",row.names = FALSE, na = "",
col.names = TRUE, sep = ",")
write.table(mtcars, file = "mtcars.csv",row.names = FALSE, na = "",
col.names = TRUE, sep = ",")
# Read the "mtcars" data frame as a csv file and store only the columns
"cyl", "am" and "gear".
write.table(mtcars, file = "mtcars.csv",row.names = FALSE, na = "",
col.names = TRUE, sep = ",")
# Store 5 records from the csv file as a new data frame.
new.mtcars <- read.table("mtcars.csv",sep = ",",header = TRUE,nrows = 5)
# Create a connection object to write the binary file using mode "wb".
write.filename = file("/web/com/binmtcars.dat", "wb")
# Write the column names of the data frame to the connection object.
writeBin(colnames(new.mtcars), write.filename)
# Write the records in each of the column to the file.
writeBin(c(new.mtcars$cyl,new.mtcars$am,new.mtcars$gear), write.filename)
# Close the file for writing so that it can be read by other program.
close(write.filename)
install.packages("rjson")
# Load the package required to read JSON files.
library("rjson")
# Give the input file name to the function.
result <- fromJSON(file = "input.json")
# Give the input file name to the function.
result <- fromJSON(file = "input.json")
# Print the result.
print(result)
library("rjson")
result <- fromJSON(file = "input.json")
library("rjson")
result <- fromJSON(file = "input.json")
library("rjson")
result <- fromJSON(file = "input.json")
print(result)
#Konversi JSON ke Bingkai Data
# Load the package required to read JSON files.
library("rjson")
# Give the input file name to the function.
result <- fromJSON(file = "input.json")
# Convert JSON file to a data frame.
json_data_frame <- as.data.frame(result)
print(json_data_frame)
install.packages("RCurl")
install.packages("XML")
install.packages("stringr")
install.packages("plyr")
#Input Data
#Read the URL.
url <- "http://www.geos.ed.ac.uk/~weather/jcmb_ws/"
# Gather the html links present in the webpage.
links <- getHTMLLinks(url)
# Identify only the links which point to the JCMB 2015 files.
filenames <- links[str_detect(links, "JCMB_2015")]
# Store the file names as a list.
filenames_list <- as.list(filenames)
# Create a function to download the files by passing the URL and filename list.
downloadcsv <- function (mainurl,filename) {
filedetails <- str_c(mainurl,filename)
download.file(filedetails,filename)
}
# Now apply the l_ply function and save the files into the current R working directory.
l_ply(filenames,downloadcsv,mainurl = "http://www.geos.ed.ac.uk/~weather/jcmb_ws/")
links <- getHTMLLinks(url)
links <- getHTMLLinks(url)
url <- "http://www.geos.ed.ac.uk/~weather/jcmb_ws/"
links <- getHTMLLinks(url)
#Input Data
#Read the URL.
url <- "http://www.omegahat.net"
# Gather the html links present in the webpage.
links <- getHTMLLinks(url)
library("RCurl")
library("XML")
library("stringr")
library("plyr")
url <- "http://www.omegahat.net"
links <- getHTMLLinks(url)
url <- "http://www.geos.ed.ac.uk/~weather/jcmb_ws/"
links <- getHTMLLinks(url)
url <- "http://www.omegahat.net"
links <- getHTMLLinks(url)
url <- "https://www.bps.go.id/dynamictable/2015/09/18/906/jumlah-desa-kelurahan-menurut-provinsi-dan-letak-geografi-2003---2018.html"
# Gather the html links present in the webpage.
links <- getHTMLLinks(url)
url <- "https://www.bps.go.id/"
# Gather the html links present in the webpage.
links <- getHTMLLinks(url)
url <- "https://www.bps.go.id/site/resulttab"
# Gather the html links present in the webpage.
links <- getHTMLLinks(url)
url <- "https://data.go.id/dataset/cuaca-dan-curah-hujan-kota-bandung-tahun-2013"
# Gather the html links present in the webpage.
links <- getHTMLLinks(url)
install.packages("RMySQL")
library(RMySQL)
Create a connection Object to MySQL database.
# We will connect to the sampel database named "sakila" that comes with MySql installation.
mysqlconnection = dbConnect(MySQL(), user = 'root', password = '', dbname = 'sakila',
host = 'localhost')
